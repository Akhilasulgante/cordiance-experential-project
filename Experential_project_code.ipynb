{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2882d893-371b-4570-9919-a02b51695402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anytree in c:\\users\\kasiv\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\kasiv\\anaconda3\\lib\\site-packages (from anytree) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install anytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f821f4bb-dd9a-40b4-9a3f-3ca64e467804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kasiv\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\kasiv\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\kasiv\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kasiv\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kasiv\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kasiv\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c287e78-b81f-4485-99d5-af23cf948f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inflect in c:\\users\\kasiv\\anaconda3\\lib\\site-packages (5.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install inflect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfd2c2-6cc3-477d-96b1-42e656087731",
   "metadata": {},
   "source": [
    "# Importingnltk.download('punkt')\n",
    "nltk.download('stopwords') Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c22c96cd-27ae-42e7-9b17-8b849ba6459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kasiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kasiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2198a4d-b4cf-4ac9-88e6-10534f411287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from anytree import Node, RenderTree\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import inflect\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18cb2df6-faca-4dab-9796-c5449ea769c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0907c139-5dcb-446d-8821-68fb8b1b6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\"Else\",\"Facilities\",\"Associated\",\"less\",\"service\",\"Premium\",\"Processing\",\"Product\",\"Provide\",\"Includes\",\"supply\",\"Standard\",\"new\",\"class\",\"group\",\"offer\",\"package\",\"facility\",\"accessory\",\"part\",\"customer\",\"function\",\"management\",\"station\",\"block\",\"personal\",\"material\",\"machinary\",\"storage\",\"warehouse\"]\n",
    "custom_stop_words_singular=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dbaa0dc1-f4f8-409e-9526-cfb5331d2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    " for word in custom_stop_words:\n",
    "        ele = p.singular_noun(word)\n",
    "        if type(ele) == str:\n",
    "            custom_stop_words_singular.append(ele.lower())\n",
    "        else:\n",
    "            custom_stop_words_singular.append(word.lower())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "80fb0a7b-4605-465f-8db7-9c7fad82625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= set(stopwords.words(\"english\") + custom_stop_words_singular)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc7e9d4-35d0-436e-a2d2-3729b930b9ea",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2fa6f044-8044-4c43-a97f-8c00d608c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(data):\n",
    "  data = data.encode('ascii', 'ignore').decode()\n",
    "  data = re.sub(r'\\'\\w+', '', data)\n",
    "  data = re.sub('[%s]' % re.escape(string.punctuation), ' ', data)\n",
    "  data = re.sub(r'\\w*\\d+\\w*', '', data)\n",
    "  data = re.sub(r'\\s{2,}', ' ', data)\n",
    "  data = data.lower()\n",
    "    \n",
    "  clensed_data = \"\"\n",
    "  for word in data.split(' '):\n",
    "     singular = p.singular_noun(word)\n",
    "     if type(singular) != str :\n",
    "            singular = word\n",
    "     if singular not in stop_words:        \n",
    "            clensed_data += singular + \" \"\n",
    "            \n",
    "  return clensed_data.rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba8377-6c2c-4ef6-b366-b2a7d10d8ac5",
   "metadata": {},
   "source": [
    "# Levels to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78778ff3-bec7-4eaa-84b3-2019d48dbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=[[\"Segment Title\",\"Segment\"],[\"Family Title\",\"Family\"],[\"Class Title\",\"Class\"],[\"Commodity Title\",\"Commodity\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9710c2-1446-42fc-895b-628a09b977e2",
   "metadata": {},
   "source": [
    "# Key Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3e99900f-f9e2-4690-af41-9067ae92eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create the key representing the start char of every word in the sentence like if the sentence is like \"can we create the key and find similar keys?\" in the alphabet sequence array\n",
    "# The advantage of this approach is that we can find the similar keys in short time\n",
    "# The first_char_array_title will contains [c,w,t,k,a,f,s] unique values\n",
    "# The key will be 10100100001000000011001000 because we assign \n",
    "# \n",
    "# for Char 'c' => arr[2]=1 ; Char 'w' => arr[22]=1 ; Char 't' => arr[19]=1 ; Char 'k' => arr[10]=1 ; Char 'a' => arr[0]=1 ; Char 'f' => arr[5]=1 ; Char 's' => arr[18]=1 ; \n",
    "\n",
    "def create_node_key(title):\n",
    "\n",
    "    char_array = ['0']*26\n",
    "    first_char_array_title =set(map(lambda x: x[0] ,filter(lambda x:x!=\"\",title.strip().split(' '))))\n",
    "\n",
    "    for start_char in first_char_array_title:\n",
    "        index= ord(start_char.lower()) - ord('a')\n",
    "        if  index >=0 and index<=25:\n",
    "            char_array[index] = '1'\n",
    "\n",
    "    key = \"\".join(char_array)\n",
    "    return key\n",
    "\n",
    "# We are finding the similar keys by making the key into binary format and simply using the bitwise and operator to see if the values !=0 which means the key1 and key2 are having similar keys\n",
    "def cmp_key(key1,key2):\n",
    "    return (eval('0b' + key1) & eval('0b' + key2) !=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9c57c-d81b-4d36-918b-d058607c010b",
   "metadata": {},
   "source": [
    "# Extracting UNSPSC File and store the data in tree format using <b>AnyTree Library</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cae34a-c336-4087-9800-086518eb54de",
   "metadata": {},
   "source": [
    "## Tree pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "10c483f5-dcbc-4ebf-885a-1850316d44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Root Node\n",
    "root=Node(\"root\")\n",
    "nodes={}\n",
    "nodes[root.name]=root\n",
    "\n",
    "#Pointer to the levels\n",
    "tree_pointer = {}\n",
    "tree_pointer [\"Segment Title\"]={}\n",
    "tree_pointer [\"Family Title\"]={}\n",
    "tree_pointer [\"Class Title\"]={}\n",
    "tree_pointer [\"Commodity Title\"]={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb4dd7-577e-452e-9c65-1f9007ebe1e0",
   "metadata": {},
   "source": [
    "## Creating Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c1d0751f-5abe-47da-9d6d-3140b286c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Node(data,title):\n",
    "  global tree_pointer\n",
    "  parent_key=\"\"\n",
    "  if (data[\"key\"].strip()==''):\n",
    "      return\n",
    "\n",
    "  node_key = create_node_key(data['title'])\n",
    "  if node_key in tree_pointer[title]:\n",
    "    parent_key = tree_pointer[title][node_key]\n",
    "\n",
    "  else:\n",
    "     tree_pointer[title][node_key] = Node(node_key,parent=nodes[title])\n",
    "     parent_key =  tree_pointer[title][node_key]\n",
    "\n",
    "  if not data[\"title\"] in set(map(lambda child: child.name,parent_key.children)):   \n",
    "      Node(data[\"title\"],parent=parent_key,data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b234b2d-c75d-4e34-9d85-7e7099f52952",
   "metadata": {},
   "source": [
    "## load UNSPSC File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7abcead-0f66-4301-9323-1ec1f7771bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('UNSPSC_English.csv',encoding=\"utf8\")  as unspsc_file:\n",
    "    [ next(unspsc_file) for _ in range(9)]   \n",
    "    unspsc_reader = csv.DictReader(unspsc_file, delimiter=',')\n",
    "    [ next(unspsc_reader) for _ in range(2)] \n",
    "    for title in titles:\n",
    "      nodes[title[0]] = Node(title[0],parent=root)\n",
    "\n",
    "    for line in unspsc_reader:\n",
    "      for index in range(0,len(titles)):\n",
    "        create_Node({\"title\" : text_preprocessing(line[titles[index][0]]),\"key\":line[titles[index][1]]},titles[index][0]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d3f5c-ba84-4c1e-9f9c-4d80bad0e879",
   "metadata": {},
   "source": [
    "## Unique Values of titles in UNSPSC File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "54e53711-fbe5-4386-8944-68d857aed31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segement Title Leaves Count:  57                  Segement Title Children Count:  54\n",
      "Family Title Leaves Count:  541                   Family Title Children Count:  363\n",
      "Class Title Leaves Count:  7796                   Class Title Children Count:  2957\n",
      "Commodity Title Leaves Count:  146404             Commodity Title Children Count:  25782\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Segement Title Leaves Count: \",len(nodes[\"Segment Title\"].leaves),\"                 Segement Title Children Count: \",len(nodes[\"Segment Title\"].children))\n",
    "\n",
    "print(\"Family Title Leaves Count: \",len(nodes[\"Family Title\"].leaves),\"                  Family Title Children Count: \",len(nodes[\"Family Title\"].children))\n",
    "\n",
    "print(\"Class Title Leaves Count: \",len(nodes[\"Class Title\"].leaves),\"                  Class Title Children Count: \",len(nodes[\"Class Title\"].children))\n",
    "\n",
    "print(\"Commodity Title Leaves Count: \",len(nodes[\"Commodity Title\"].leaves),\"            Commodity Title Children Count: \",len(nodes[\"Commodity Title\"].children))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7200242-6abd-4be4-aead-d19b6ba30bcf",
   "metadata": {},
   "source": [
    "# Load Avalara File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f58cd62-8141-4f1e-996e-12b57eba35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Avalara_goods_and_services.xlsx', header=1)\n",
    "data_array = np.array(df)\n",
    "avalara_file = data_array[1706:2547]\n",
    "avalara_file=avalara_file[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d175a65-b02a-4034-9b09-1691397518c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avalara File text preprocessing and the create the key from the desc\n",
    "text_preprocessing_vf = np.vectorize(text_preprocessing)\n",
    "create_node_key_vf = np.vectorize(create_node_key)\n",
    "avalara_file = np.column_stack((avalara_file,text_preprocessing_vf(avalara_file[:,1])))\n",
    "avalara_file = np.column_stack((avalara_file,create_node_key_vf(avalara_file[:,3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381dc3e3-6a06-42a4-9fcc-cfeafea93d05",
   "metadata": {},
   "source": [
    "# Searching the tree based on the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "30c93064-60ef-4cd6-8454-7de3ea9a31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the key matches b/w avalara and UNSPSC\n",
    "def search_tree(key,level):\n",
    "    key_match = {}    \n",
    "    for child in nodes[level].children:\n",
    "          if(cmp_key(child.name,key)):\n",
    "            key_match[child.name] = child.children\n",
    "    \n",
    "    return key_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d152e2-647f-4e55-b9f4-f52f88b9e9d3",
   "metadata": {},
   "source": [
    "# LCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4f64ea3-b2e1-4f50-ae9d-0d1653900ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longestCommonSubsequence(text1, text2):\n",
    "\n",
    "    text1 = text1.lower().split(\" \")\n",
    "    text2 = text2.lower().split(\" \")\n",
    "    \n",
    "    if len(text1) > len(text2):\n",
    "        text2,text1 = text1,text2  \n",
    "    arr = [[0 for i in range(len(text2)+1)] for j in range(2)]\n",
    "    \n",
    "    b=1\n",
    "    for i in range (1,len(text1)+1):    \n",
    "        b= i & 1\n",
    "        for j in range(1,len(text2)+1):\n",
    "            if text1[i-1] == text2[j-1]:\n",
    "                arr[1-b][j]= arr[b][j-1]+1\n",
    "            else:\n",
    "                arr[1-b][j] = max(arr[b][j],arr[1-b][j-1])\n",
    "    \n",
    "    return arr[1-b][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781ad51f-9cb9-4e51-8aba-a6a230e46728",
   "metadata": {},
   "source": [
    "# Main function for finding the match ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6dd55042-1376-47da-8920-4e6010f4a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update thresold to change the accuracy\n",
    "def try_function_parallel_all_levels(data,ans):\n",
    "    levels = [\"Commodity Title\",\"Class Title\",\"Family Title\",\"Segment Title\"]\n",
    "    for index,level in enumerate(levels):\n",
    "      for match_parent in (search_tree(data[4],level)).values():\n",
    "        for match in match_parent:\n",
    "            avalara_desc = data[3] \n",
    "            avalara_key = data[0] \n",
    "            if not isinstance(avalara_key,str):\n",
    "                return\n",
    "            unspsc_desc = match.data[\"title\"]\n",
    "            unspsc_key = match.data[\"key\"]\n",
    "            avalara_length = len(avalara_desc.split(\" \"))\n",
    "            unspsc_length = len(unspsc_desc.split(\" \"))\n",
    "            min_length = unspsc_length if (avalara_length > unspsc_length) else avalara_length\n",
    "            max_length = unspsc_length if (avalara_length < unspsc_length) else avalara_length\n",
    "            thresold = 0.5\n",
    "            lcs = longestCommonSubsequence(unspsc_desc,avalara_desc)\n",
    "            match_perc_min = lcs/min_length\n",
    "            match_perc_max = lcs/max_length\n",
    "            if (match_perc_min >= thresold):\n",
    "                if avalara_desc in ans:\n",
    "                  if level in ans[avalara_desc]:\n",
    "                    ans[avalara_desc][level].append({\"unspsc_text\" : unspsc_desc,\"unspsc_key\":unspsc_key,\"match_ratio_min\" : match_perc_max,\"match_ratio_max\":match_perc_min })\n",
    "                  else:\n",
    "                    ans[avalara_desc][level] = []\n",
    "                    ans[avalara_desc][level].append({\"unspsc_text\" : unspsc_desc,\"unspsc_key\":unspsc_key,\"match_ratio_min\" : match_perc_max,\"match_ratio_max\":match_perc_min })\n",
    "                else:\n",
    "                  ans[avalara_desc] ={\"key\":avalara_key}\n",
    "                  ans[avalara_desc][level] = []\n",
    "                  ans[avalara_desc][level].append({\"unspsc_text\" : unspsc_desc,\"unspsc_key\":unspsc_key,\"match_ratio_min\" : match_perc_max,\"match_ratio_max\":match_perc_min})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf453c8-5fe8-46f6-a2dd-cfc59e274db4",
   "metadata": {},
   "source": [
    "# Multiprocessing Finding match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301eba20-22bc-4cd8-ab38-3edfd5b3c810",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Ans is all the possibilities of the match\n",
    "ans = {}\n",
    "total_length_avalara_file = len(avalara_file)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores, verbose=10,require='sharedmem')(delayed(try_function_parallel_all_levels)(i,ans) for i in avalara_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5f18bb8-8c7c-40b0-a318-001de25e3798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Result is where we can find best match for each level\n",
    "levels = [\"Commodity Title\",\"Family Title\",\"Class Title\",\"Segment Title\"]\n",
    "best_result = {}\n",
    "for desc in ans:\n",
    "    for level in levels:\n",
    "        try:\n",
    "            if desc not in best_result:\n",
    "                best_result[desc] = {}\n",
    "                best_result[desc][level]=(sorted(sorted(list(map(lambda x : {\"data\":x,\"normalized_value\":(1-x[\"match_ratio_max\"])*(x[\"match_ratio_max\"]-x[\"match_ratio_min\"])} ,ans[desc][level])),key=lambda x:x[\"normalized_value\"]),key=lambda x:x[\"data\"][\"match_ratio_min\"],reverse=True)[0]) \n",
    "            else:\n",
    "                best_result[desc][level]=(sorted(sorted(list(map(lambda x : {\"data\":x,\"normalized_value\":(1-x[\"match_ratio_max\"])*(x[\"match_ratio_max\"]-x[\"match_ratio_min\"])} ,ans[desc][level])),key=lambda x:x[\"normalized_value\"]),key=lambda x:x[\"data\"][\"match_ratio_min\"],reverse=True)[0]) \n",
    "        except:\n",
    "            continue\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9fd7cce7-fc5e-4470-9722-0b9a98121a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final result is where we can find the most accurate match in all the levels\n",
    "final_result ={}\n",
    "for avalara_desc in best_result: \n",
    "    final_result[avalara_desc] = sorted(best_result[avalara_desc].items(), key=lambda k: k[1]['data']['match_ratio_min'],reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f775f-0e0d-4cb8-a81f-95d249eda21b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
